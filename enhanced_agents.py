"""
å¢å¼ºæ™ºèƒ½ä½“ç³»ç»Ÿ - å…·æœ‰è‡ªä¸»å†³ç­–å’Œè‡ªæˆ‘åæ€èƒ½åŠ›çš„AIåŠ©æ‰‹ï¼ˆä¿®å¤ç‰ˆï¼‰

æœ¬ç³»ç»Ÿå®ç°äº†ä¸€ä¸ªçœŸæ­£ç”±LLMé©±åŠ¨çš„æ™ºèƒ½ä½“ï¼š
1. LLMé©±åŠ¨çš„æ§åˆ¶æµï¼šæ¯ä¸€æ­¥çš„å†³ç­–éƒ½ç”±LLMåšå‡º
2. è‡ªæˆ‘åæ€æœºåˆ¶ï¼šæ¯æ¬¡æ‰§è¡Œåè¯„ä¼°ç»“æœå¹¶è°ƒæ•´ç­–ç•¥
3. LangChain Agentæ¶æ„ï¼šä½¿ç”¨å·¥å…·æ¡†æ¶å®ç°çµæ´»çš„åŠŸèƒ½æ‰©å±•
4. åŠ¨æ€è®¡åˆ’è°ƒæ•´ï¼šæ ¹æ®æ‰§è¡Œç»“æœå®æ—¶ä¿®æ­£è®¡åˆ’
"""

import json
import re
from typing import Any, Dict, List, Optional, Union
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_community.chat_models import ChatOpenAI
from langchain_core.tools import BaseTool
from langchain_core.callbacks import CallbackManagerForToolRun
from api_setting import API_KEY, API_URL, API_MODEL

# ==================== æ™ºèƒ½ä½“çŠ¶æ€å®šä¹‰ ====================
class EnhancedAgentState:
    """
    å¢å¼ºæ™ºèƒ½ä½“çš„çŠ¶æ€ç®¡ç†
    
    ç›¸æ¯”åŸç‰ˆï¼Œå¢åŠ äº†ï¼š
    - reflection_history: è‡ªæˆ‘åæ€å†å²
    - replan_count: é‡æ–°è§„åˆ’æ¬¡æ•°
    - current_focus: å½“å‰å…³æ³¨ç‚¹
    - confidence_score: æ‰§è¡Œä¿¡å¿ƒåˆ†æ•°
    """
    def __init__(self, objective: str):
        self.objective = objective
        self.plan: List[str] = []
        self.completed_tasks: List[Dict] = []
        self.reflection_history: List[str] = []
        self.messages: List[BaseMessage] = []
        self.replan_count = 0
        self.current_focus = ""
        self.confidence_score = 0.0
        self.status = "initializing"  # initializing, planning, executing, reflecting, completed
    
    def to_dict(self) -> Dict:
        """å°†çŠ¶æ€è½¬æ¢ä¸ºå­—å…¸ï¼Œä¾¿äºä¼ é€’ç»™LLM"""
        return {
            "objective": self.objective,
            "plan": self.plan,
            "completed_tasks": self.completed_tasks,
            "reflection_history": self.reflection_history,
            "replan_count": self.replan_count,
            "current_focus": self.current_focus,
            "confidence_score": self.confidence_score,
            "status": self.status,
            "progress": f"{len(self.completed_tasks)}/{len(self.plan)}" if self.plan else "0/0"
        }

# ==================== è‡ªå®šä¹‰å·¥å…·å®šä¹‰ ====================
class PlanningTool(BaseTool):
    """è§„åˆ’å·¥å…·ï¼šç”Ÿæˆæˆ–ä¿®æ­£ä»»åŠ¡è®¡åˆ’"""
    name: str = "planning_tool"
    description: str = "Create or revise a task plan based on the objective and current situation"
    
    def __init__(self, llm, **kwargs):
        super().__init__(**kwargs)
        self._llm = llm
        self._prompt = ChatPromptTemplate.from_messages([
            ("system", """You are an expert task planner. Given an objective and current context, create a detailed action plan.

Your plan should:
1. Break down the objective into 3-7 concrete, actionable steps
2. Consider the current progress and any lessons learned
3. Ensure each step is specific and measurable
4. Arrange steps in logical order

Format your response as a JSON object:
{{
    "plan": [
        "Step 1: Specific action description",
        "Step 2: Another specific action"
    ],
    "reasoning": "Brief explanation of your planning approach",
    "estimated_difficulty": "low/medium/high"
}}
"""),
            ("human", "Objective: {objective}\nCurrent Context: {context}")
        ])
    
    def _run(self, objective: str, context: str = "", run_manager: Optional[CallbackManagerForToolRun] = None) -> str:
        messages = self._prompt.invoke({"objective": objective, "context": context})
        result = self._llm.invoke(messages)
        # æ¸…ç†å¯èƒ½å­˜åœ¨çš„ Markdown ä»£ç å—
        raw_content = result.content.strip()
        cleaned = re.sub(r"^```(?:json)?\s*", "", raw_content)
        cleaned = re.sub(r"```$", "", cleaned).strip()
        return cleaned

class ExecutionTool(BaseTool):
    """æ‰§è¡Œå·¥å…·ï¼šæ‰§è¡Œå…·ä½“ä»»åŠ¡"""
    name: str = "execution_tool"
    description: str = "Execute a specific task and return detailed results"
    
    def __init__(self, llm, **kwargs):
        super().__init__(**kwargs)
        self._llm = llm
        self._prompt = ChatPromptTemplate.from_messages([
            ("system", """You are an expert task executor. Given a specific task, execute it thoroughly and provide detailed results.

Your execution should include:
1. Clear understanding of what needs to be done
2. Step-by-step execution process
3. Specific outcomes and observations
4. Any challenges encountered
5. Quality assessment of the results

Format your response as a JSON object:
{{
    "execution_process": "Detailed description of how you executed the task",
    "results": "Specific outcomes and deliverables",
    "challenges": "Any difficulties or obstacles encountered",
    "quality_score": 0.8,
    "recommendations": "Suggestions for improvement or next steps"
}}
"""),
            ("human", "Task: {task}\nContext: {context}")
        ])
    
    def _run(self, task: str, context: str = "", run_manager: Optional[CallbackManagerForToolRun] = None) -> str:
        messages = self._prompt.invoke({"task": task, "context": context})
        result = self._llm.invoke(messages)
        # æ¸…ç†å¯èƒ½å­˜åœ¨çš„ Markdown ä»£ç å—
        raw_content = result.content.strip()
        cleaned = re.sub(r"^```(?:json)?\s*", "", raw_content)
        cleaned = re.sub(r"```$", "", cleaned).strip()
        return cleaned

class ReflectionTool(BaseTool):
    """åæ€å·¥å…·ï¼šè¯„ä¼°æ‰§è¡Œç»“æœå¹¶æä¾›æ”¹è¿›å»ºè®®"""
    name: str = "reflection_tool"
    description: str = "Reflect on recent execution results and provide insights for improvement"
    
    def __init__(self, llm, **kwargs):
        super().__init__(**kwargs)
        self._llm = llm
        self._prompt = ChatPromptTemplate.from_messages([
            ("system", """You are an expert performance evaluator. Analyze recent task execution and provide valuable insights.

Your reflection should include:
1. Assessment of what went well and what didn't
2. Identification of patterns or recurring issues
3. Specific recommendations for improvement
4. Strategic insights for future planning
5. Confidence level in current approach

Format your response as a JSON object:
{{
    "assessment": "Overall evaluation of recent performance",
    "strengths": ["What worked well"],
    "weaknesses": ["Areas for improvement"],
    "patterns": ["Notable patterns observed"],
    "recommendations": ["Specific suggestions for improvement"],
    "confidence_adjustment": 0.1,
    "should_replan": true
}}
"""),
            ("human", "Recent Execution History: {history}\nCurrent Plan: {plan}\nObjective: {objective}")
        ])
    
    def _run(self, history: str, plan: str, objective: str, run_manager: Optional[CallbackManagerForToolRun] = None) -> str:
        messages = self._prompt.invoke({"history": history, "plan": plan, "objective": objective})
        result = self._llm.invoke(messages)
        # æ¸…ç†å¯èƒ½å­˜åœ¨çš„ Markdown ä»£ç å—
        raw_content = result.content.strip()
        cleaned = re.sub(r"^```(?:json)?\s*", "", raw_content)
        cleaned = re.sub(r"```$", "", cleaned).strip()
        return cleaned

# ==================== LLMé©±åŠ¨çš„æ§åˆ¶å™¨ ====================
class LLMController:
    """
    LLMé©±åŠ¨çš„æ™ºèƒ½ä½“æ§åˆ¶å™¨
    
    æ ¸å¿ƒç‰¹æ€§ï¼š
    1. æ¯ä¸€æ­¥çš„å†³ç­–éƒ½ç”±LLMåšå‡º
    2. æ ¹æ®å½“å‰çŠ¶æ€åŠ¨æ€é€‰æ‹©ä¸‹ä¸€ä¸ªè¡ŒåŠ¨
    3. æ”¯æŒå¾ªç¯ã€è·³è·ƒã€é‡æ–°è§„åˆ’ç­‰å¤æ‚æ§åˆ¶æµ
    """
    def __init__(self, llm):
        self.llm = llm
        self.decision_prompt = ChatPromptTemplate.from_messages([
            ("system", """You are the central controller of an intelligent agent system. Your role is to analyze the current situation and decide the next best action.

Available actions:
1. "plan" - Create or revise the task plan
2. "execute" - Execute the next task in the plan
3. "reflect" - Analyze recent performance and adjust strategy
4. "replan" - Completely revise the plan based on new insights
5. "complete" - Mark the objective as completed

Consider:
- Current progress and remaining work
- Quality of recent executions
- Whether the current plan is still optimal
- Any patterns in the execution history

Respond with a JSON object:
{{
    "action": "plan|execute|reflect|replan|complete",
    "reasoning": "Detailed explanation of why this action is best",
    "parameters": {{}},
    "confidence": 0.8,
    "urgency": "low|medium|high"
}}"""),
            ("human", "Current State: {state}\nRecent History: {history}")
        ])
    
    def decide_next_action(self, state: EnhancedAgentState) -> Dict:
        """è®©LLMå†³å®šä¸‹ä¸€æ­¥è¡ŒåŠ¨"""
        # å‡†å¤‡çŠ¶æ€ä¿¡æ¯
        state_info = state.to_dict()
        
        # å‡†å¤‡æœ€è¿‘çš„å†å²ä¿¡æ¯
        recent_history = []
        if state.completed_tasks:
            recent_history = state.completed_tasks[-3:]  # æœ€è¿‘3ä¸ªä»»åŠ¡
        if state.reflection_history:
            recent_history.extend(state.reflection_history[-2:])  # æœ€è¿‘2æ¬¡åæ€
        
        # è°ƒç”¨LLMè¿›è¡Œå†³ç­–
        messages = self.decision_prompt.invoke({
            "state": json.dumps(state_info, indent=2, ensure_ascii=False),
            "history": json.dumps(recent_history, indent=2, ensure_ascii=False)
        })
        
        result = self.llm.invoke(messages)
        
        # æ¸…ç†å¯èƒ½å­˜åœ¨çš„ Markdown ä»£ç å—
        raw_content = result.content.strip()
        cleaned = re.sub(r"^```(?:json)?\s*", "", raw_content)
        cleaned = re.sub(r"```$", "", cleaned).strip()
        
        try:
            decision = json.loads(cleaned)
            return decision
        except json.JSONDecodeError:
            # å¦‚æœJSONè§£æå¤±è´¥ï¼Œè¿”å›é»˜è®¤å†³ç­–
            return {
                "action": "reflect",
                "reasoning": "Failed to parse decision, defaulting to reflection",
                "parameters": {},
                "confidence": 0.3,
                "urgency": "medium"
            }

# ==================== å¢å¼ºæ™ºèƒ½ä½“ä¸»ç±» ====================
class EnhancedAgent:
    """
    å¢å¼ºç‰ˆæ™ºèƒ½ä½“ - å…·æœ‰è‡ªä¸»å†³ç­–å’Œè‡ªæˆ‘åæ€èƒ½åŠ›
    
    æ ¸å¿ƒæ”¹è¿›ï¼š
    1. LLMé©±åŠ¨çš„æ§åˆ¶æµ
    2. è‡ªæˆ‘åæ€æœºåˆ¶
    3. åŸºäºLangChainå·¥å…·çš„æ¨¡å—åŒ–æ¶æ„
    """
    def __init__(self):
        # åˆå§‹åŒ–LLMï¼ˆç¨é«˜çš„æ¸©åº¦ä»¥æ”¯æŒåˆ›é€ æ€§å†³ç­–ï¼‰
        self.llm = ChatOpenAI(
            model=API_MODEL,
            temperature=0.3,
            api_key=API_KEY,
            base_url=API_URL
        )
        
        # åˆå§‹åŒ–æ§åˆ¶å™¨
        self.controller = LLMController(self.llm)
        
        # åˆå§‹åŒ–å·¥å…·
        self.planning_tool = PlanningTool(self.llm)
        self.execution_tool = ExecutionTool(self.llm)
        self.reflection_tool = ReflectionTool(self.llm)
        
        # åˆ›å»ºå·¥å…·åˆ—è¡¨
        self.tools = [
            self.planning_tool,
            self.execution_tool,
            self.reflection_tool
        ]
    
    def run(self, objective: str, max_iterations: int = 20) -> Dict:
        """
        è¿è¡Œå¢å¼ºæ™ºèƒ½ä½“
        
        Args:
            objective: ç”¨æˆ·ç›®æ ‡
            max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°
            
        Returns:
            Dict: åŒ…å«æ‰§è¡Œç»“æœçš„å­—å…¸
        """
        print("ğŸš€ å¯åŠ¨å¢å¼ºæ™ºèƒ½ä½“...")
        print(f"ğŸ¯ ç›®æ ‡: {objective}")
        print("=" * 60)
        
        # åˆå§‹åŒ–çŠ¶æ€
        state = EnhancedAgentState(objective)
        iteration_count = 0
        
        while iteration_count < max_iterations:
            iteration_count += 1
            print(f"\nğŸ”„ ç¬¬ {iteration_count} è½®å†³ç­–")
            
            # LLMå†³ç­–ä¸‹ä¸€æ­¥è¡ŒåŠ¨
            decision = self.controller.decide_next_action(state)
            action = decision.get("action", "reflect")
            reasoning = decision.get("reasoning", "No reasoning provided")
            confidence = decision.get("confidence", 0.5)
            
            print(f"ğŸ¤” LLMå†³ç­–: {action}")
            print(f"ğŸ’­ å†³ç­–ç†ç”±: {reasoning}")
            print(f"ğŸ¯ ä¿¡å¿ƒåˆ†æ•°: {confidence:.2f}")
            
            # æ›´æ–°çŠ¶æ€
            state.confidence_score = confidence
            state.status = action
            
            # æ‰§è¡Œç›¸åº”åŠ¨ä½œ
            if action == "plan" or action == "replan":
                self._handle_planning(state, action == "replan")
                
            elif action == "execute":
                self._handle_execution(state)
                
            elif action == "reflect":
                self._handle_reflection(state)
                
            elif action == "complete":
                print("âœ… LLMåˆ¤æ–­ç›®æ ‡å·²å®Œæˆï¼")
                break
                
            else:
                print(f"âš ï¸ æœªçŸ¥åŠ¨ä½œ: {action}ï¼Œåˆ‡æ¢åˆ°åæ€æ¨¡å¼")
                self._handle_reflection(state)
            
            # å®‰å…¨æ£€æŸ¥ï¼šå¦‚æœé™·å…¥å¾ªç¯ï¼Œå¼ºåˆ¶é€€å‡º
            if iteration_count >= max_iterations:
                print("âš ï¸ è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œå¼ºåˆ¶ç»“æŸ")
                break
        
        print("\n" + "=" * 60)
        print("ğŸ‰ æ™ºèƒ½ä½“æ‰§è¡Œå®Œæˆï¼")
        
        # è¿”å›æœ€ç»ˆç»“æœ
        return {
            "objective": objective,
            "completed_tasks": state.completed_tasks,
            "reflections": state.reflection_history,
            "final_confidence": state.confidence_score,
            "iterations_used": iteration_count,
            "status": "completed" if action == "complete" else "max_iterations_reached"
        }
    
    def _handle_planning(self, state: EnhancedAgentState, is_replan: bool = False):
        """å¤„ç†è§„åˆ’åŠ¨ä½œ"""
        action_type = "é‡æ–°è§„åˆ’" if is_replan else "åˆå§‹è§„åˆ’"
        print(f"ğŸ“‹ æ‰§è¡Œ{action_type}...")
        
        # å‡†å¤‡ä¸Šä¸‹æ–‡
        context = {
            "completed_tasks": state.completed_tasks,
            "reflections": state.reflection_history,
            "replan_count": state.replan_count
        }
        
        # è°ƒç”¨è§„åˆ’å·¥å…·
        result = self.planning_tool._run(
            objective=state.objective,
            context=json.dumps(context, ensure_ascii=False)
        )
        
        try:
            plan_data = json.loads(result)
            state.plan = plan_data.get("plan", [])
            
            if is_replan:
                state.replan_count += 1
            
            print(f"âœ… {action_type}å®Œæˆï¼Œå…± {len(state.plan)} ä¸ªä»»åŠ¡:")
            for i, task in enumerate(state.plan, 1):
                print(f"   {i}. {task}")
            
            # è®°å½•åˆ°æ¶ˆæ¯å†å²
            state.messages.append(HumanMessage(content=f"{action_type}: {len(state.plan)} tasks created"))
            
        except json.JSONDecodeError:
            print("âŒ è§„åˆ’ç»“æœè§£æå¤±è´¥ï¼Œä¿æŒåŸè®¡åˆ’")
    
    def _handle_execution(self, state: EnhancedAgentState):
        """å¤„ç†æ‰§è¡ŒåŠ¨ä½œ"""
        if not state.plan:
            print("âŒ æ²¡æœ‰å¯æ‰§è¡Œçš„è®¡åˆ’ï¼Œåˆ‡æ¢åˆ°è§„åˆ’æ¨¡å¼")
            self._handle_planning(state)
            return
        
        # æ‰¾åˆ°ä¸‹ä¸€ä¸ªæœªå®Œæˆçš„ä»»åŠ¡
        next_task_index = len(state.completed_tasks)
        if next_task_index >= len(state.plan):
            print("âœ… æ‰€æœ‰è®¡åˆ’ä»»åŠ¡å·²å®Œæˆ")
            return
        
        current_task = state.plan[next_task_index]
        print(f"ğŸš€ æ‰§è¡Œä»»åŠ¡ {next_task_index + 1}: {current_task}")
        
        # å‡†å¤‡æ‰§è¡Œä¸Šä¸‹æ–‡
        context = {
            "completed_tasks": state.completed_tasks,
            "remaining_tasks": state.plan[next_task_index + 1:],
            "objective": state.objective
        }
        
        # è°ƒç”¨æ‰§è¡Œå·¥å…·
        result = self.execution_tool._run(
            task=current_task,
            context=json.dumps(context, ensure_ascii=False)
        )
        
        try:
            execution_data = json.loads(result)
            
            # è®°å½•æ‰§è¡Œç»“æœ
            task_result = {
                "task": current_task,
                "execution_process": execution_data.get("execution_process", ""),
                "results": execution_data.get("results", ""),
                "challenges": execution_data.get("challenges", ""),
                "quality_score": execution_data.get("quality_score", 0.5),
                "recommendations": execution_data.get("recommendations", "")
            }
            
            state.completed_tasks.append(task_result)
            
            print(f"âœ… ä»»åŠ¡å®Œæˆï¼Œè´¨é‡åˆ†æ•°: {task_result['quality_score']:.2f}")
            # ç¡®ä¿ results æ˜¯å­—ç¬¦ä¸²å†è¿›è¡Œåˆ‡ç‰‡
            results_str = str(task_result.get('results', ''))
            print(f"ğŸ“‹ ç»“æœæ‘˜è¦: {results_str[:100]}...")
            
            # è®°å½•åˆ°æ¶ˆæ¯å†å²
            state.messages.append(HumanMessage(content=f"Completed task: {current_task}"))
            
        except json.JSONDecodeError:
            print("âŒ æ‰§è¡Œç»“æœè§£æå¤±è´¥ï¼Œè®°å½•åŸå§‹ç»“æœ")
            state.completed_tasks.append({
                "task": current_task,
                "results": result,
                "quality_score": 0.3
            })
    
    def _handle_reflection(self, state: EnhancedAgentState):
        """å¤„ç†åæ€åŠ¨ä½œ"""
        print("ğŸ¤” æ‰§è¡Œè‡ªæˆ‘åæ€...")
        
        if not state.completed_tasks:
            print("âš ï¸ æš‚æ— æ‰§è¡Œå†å²ï¼Œè·³è¿‡åæ€")
            return
        
        # è°ƒç”¨åæ€å·¥å…·
        result = self.reflection_tool._run(
            history=json.dumps(state.completed_tasks, ensure_ascii=False),
            plan=json.dumps(state.plan, ensure_ascii=False),
            objective=state.objective
        )
        
        try:
            reflection_data = json.loads(result)
            
            # è®°å½•åæ€ç»“æœ
            reflection_summary = {
                "assessment": reflection_data.get("assessment", ""),
                "strengths": reflection_data.get("strengths", []),
                "weaknesses": reflection_data.get("weaknesses", []),
                "recommendations": reflection_data.get("recommendations", []),
                "should_replan": reflection_data.get("should_replan", False)
            }
            
            state.reflection_history.append(json.dumps(reflection_summary, ensure_ascii=False))
              # è°ƒæ•´ä¿¡å¿ƒåˆ†æ•°
            confidence_adjustment = reflection_data.get("confidence_adjustment", 0)
            state.confidence_score = max(0, min(1, state.confidence_score + confidence_adjustment))
            
            print(f"âœ… åæ€å®Œæˆ")
            # ç¡®ä¿ assessment æ˜¯å­—ç¬¦ä¸²å†è¿›è¡Œåˆ‡ç‰‡
            assessment_str = str(reflection_summary.get('assessment', ''))
            print(f"ğŸ“ˆ è¯„ä¼°: {assessment_str[:100]}...")
            if reflection_summary['strengths']:
                print(f"ğŸ’ª ä¼˜åŠ¿: {', '.join(reflection_summary['strengths'][:2])}")
            if reflection_summary['weaknesses']:
                print(f"ğŸ”§ æ”¹è¿›ç‚¹: {', '.join(reflection_summary['weaknesses'][:2])}")
            
            if reflection_summary['should_replan']:
                print("ğŸ”„ åæ€å»ºè®®é‡æ–°è§„åˆ’")
            
            # è®°å½•åˆ°æ¶ˆæ¯å†å²
            state.messages.append(HumanMessage(content="Completed self-reflection"))
            
        except json.JSONDecodeError:
            print("âŒ åæ€ç»“æœè§£æå¤±è´¥")

# ==================== è¿è¡Œå…¥å£å‡½æ•° ====================
def run_enhanced_agent(objective: str, max_iterations: int = 20) -> Dict:
    """
    è¿è¡Œå¢å¼ºæ™ºèƒ½ä½“çš„å…¥å£å‡½æ•°
    
    Args:
        objective: ç”¨æˆ·ç›®æ ‡
        max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°
        
    Returns:
        Dict: æ‰§è¡Œç»“æœ
    """
    agent = EnhancedAgent()
    return agent.run(objective, max_iterations)

# ==================== æµ‹è¯•å‡½æ•° ====================
if __name__ == "__main__":
    # ç®€å•æµ‹è¯•
    test_objective = "åˆ¶å®šä¸€ä¸ªå‘¨æœ«å­¦ä¹ Pythonæ•°æ®åˆ†æçš„è®¡åˆ’ï¼Œå¹¶å¼€å§‹ç¬¬ä¸€æ­¥å­¦ä¹ "
    result = run_enhanced_agent(test_objective, max_iterations=10)
    
    print("\n" + "=" * 60)
    print("ğŸ“Š æœ€ç»ˆç»“æœæ‘˜è¦:")
    print(f"ğŸ¯ ç›®æ ‡: {result['objective']}")
    print(f"âœ… å®Œæˆä»»åŠ¡æ•°: {len(result['completed_tasks'])}")
    print(f"ğŸ¤” åæ€æ¬¡æ•°: {len(result['reflections'])}")
    print(f"ğŸ’¯ æœ€ç»ˆä¿¡å¿ƒ: {result['final_confidence']:.2f}")
    print(f"ğŸ”„ ä½¿ç”¨è¿­ä»£: {result['iterations_used']}")
    print(f"ğŸ“ˆ çŠ¶æ€: {result['status']}")
